<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="A.I.C.O">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="A.I.C.O">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A.I.C.O">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>A.I.C.O</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">A.I.C.O</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/05/13/VGG-16网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="目录">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="A.I.C.O">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/13/VGG-16网络/" itemprop="url">VGG-16网络</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-13T21:05:32+08:00">
                2019-05-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="VGG-16网络"><a href="#VGG-16网络" class="headerlink" title="VGG-16网络"></a>VGG-16网络</h1><h2 id="什么是VGG"><a href="#什么是VGG" class="headerlink" title="什么是VGG"></a>什么是VGG</h2><p>简单来说就是一个著名的卷积网络，16是指有16个带有参数的网络层，是一个带有完整的卷积层，池化层 ，全连接层的神经网络。</p>
<h2 id="如何看懂VGG-16"><a href="#如何看懂VGG-16" class="headerlink" title="如何看懂VGG-16"></a>如何看懂VGG-16</h2><p>首先我们看看官方给的文档<br><img src="/2019/05/13/VGG-16网络/./20170325221311877.png" alt="Alt text"><br>龟龟，完全看不懂，我只知道conv3-128在此处表示是128个3*3的卷积，然后这些表示什么我也不懂，所以不愧是官方的文档，告辞。</p>
<p>然后我找到了一个整个VGG-16的架构图<br><img src="/2019/05/13/VGG-16网络/./`]QFZD7GRARRHXBXGEPKVJ.png" alt="Alt text"><br>从左至右，一张彩色图片输入到网络，白色框是卷积层，红色是池化，蓝色是全连接层，棕色框是预测层。预测层的作用是将全连接层输出的信息转化为相应的类别概率，而起到分类作用。<br>可以看到 VGG16 是13个卷积层+3个全连接层叠加而成</p>
<p>好，这个时候我们就会有点蒙蔽，首先一张图他特么的怎么是个三维的？好的这个问题我也不知道为什么。但是就先这么认为他就是一个三维的。然后我们进入卷积层，他有64个3<em>3</em>3的卷积核(书上说的是3<em>3的卷积核，但是如果是3</em>3这就不对了感觉)然后我们扫完这个矩阵，就得到了64层矩阵。话不多说先贴个图<br><img src="/2019/05/13/VGG-16网络/./1557752177267.png" alt="Alt text"><br>我们假设蓝色框是一个RGB图像，橙色是一个3<em>3</em>3的卷积核，我们对一个三维的27个数求和，然后扫过去，按照第一部分算的得出来的是一维的298<em>298的矩阵（因为卷积核也是三维所以结果是一维）然后回想一下什么是Padding、前面也讲过它的概念了；所以不了一圈的圆，回到了300</em>300*1；</p>
<p>将就着理解一下为什么一个卷积核扫完就是一个一维矩阵，一共64个卷积核就形成了一个64层的矩阵</p>
<p>然后我们经过一个池化操作，小矩阵是(2,2) ，步长(2,2),指的是横向每次移动2格，纵向每次移动2格这样我们得到的矩阵就的宽高就是之前的一半。</p>
<p>再往下就同理，只不过是卷积核个数依此变为128，256，512，每次池化之后，矩阵都要缩小一半。</p>
<p>13层卷积和池化之后，数据就变成了512<em>7</em>7</p>
<p>有不懂后续再做补充。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/05/09/卷积网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="目录">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="A.I.C.O">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/09/卷积网络/" itemprop="url">什么是卷积网络</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-09T17:32:03+08:00">
                2019-05-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="卷积网络"><a href="#卷积网络" class="headerlink" title="卷积网络"></a>卷积网络</h1><p>##卷积层</p>
<p>我们先看卷积核的表达方式</p>
<blockquote>
<p>f(x) = wx + b</p>
</blockquote>
<p>然后简单了解一下卷积层的几个名词</p>
<ul>
<li>深度/depth</li>
<li>步长/stride</li>
<li>填充值/padding<br><img src="/2019/05/09/卷积网络/./深度和步长.png" alt="Alt text"></li>
</ul>
<p>填充值是什么呢？以下图为例子，比如有这么一个5<em>5的图片（一个格子一个像素），我们滑动窗口取2</em>2，步长取2，那么我们发现还剩下1个像素没法滑完，那怎么办呢？<br><img src="/2019/05/09/卷积网络/./填充值1.png" alt="Alt text"><br>那我们在原先的矩阵加了一层填充值，使得变成6*6的矩阵，那么窗口就可以刚好把所有像素遍历完。这就是填充值的作用。<img src="/2019/05/09/卷积网络/./填充值2.png" alt="Alt text"></p>
<hr>
<h3 id="卷积核"><a href="#卷积核" class="headerlink" title="卷积核"></a>卷积核</h3><p>接下来我们看看卷积核<br><img src="/2019/05/09/卷积网络/./卷积核1.png" alt="Alt text"><br>如图，现有一张图片有5×5个像素点，每个像素点只有0和1，然后提取此图片的特征，首先我们设计一个简单的卷积核，假设神经元</p>
<blockquote>
<p>w = [1,1,1,1,1,1,1,1,1]<br>b = [0]</p>
</blockquote>
<p>w 由 9 个1 组成，在此场景里，我们指用黄色部分这个3×3的方块来从左到右从上到下这9个点作为x向量与w相乘完成内积操作，并与 b 相加,整个过程就是这样:</p>
<blockquote>
<p>f(x) = 1×1 + 1×1 + 1×1 + 1×0 + 1×1 + 1×1 + 1×0 + 1×0 +1×1+ 0 = 6</p>
</blockquote>
<hr>
<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>那么左上角这个黄色小方框就会输出一个6，我们把这个6单独存入一个存储空间。了解了简单的计算方式我们看看稍微复杂点的卷积层<br><img src="/2019/05/09/卷积网络/./卷积核2.png" alt="Alt text"><br>这里的蓝色矩阵就是输入的图像，粉色矩阵就是卷积层的神经元，这里表示了有两个神经元（w0,w1）。绿色矩阵就是经过卷积运算后的输出矩阵，这里的步长设置为2。<img src="/2019/05/09/卷积网络/./卷积核3.png" alt="Alt text"><br>蓝色的矩阵(输入图像)对粉色的矩阵（filter）进行矩阵内积计算并将三个内积运算的结果与偏置值b相加（比如上面图的计算：2+（-2+1-2）+（1-2-2） + 1= 2 - 3 - 3 + 1 = -3），计算后的值就是绿框矩阵的一个元素。</p>
<p>以下展示一下卷积层的计算过程<br><img src="/2019/05/09/卷积网络/./卷积核4.gif" alt="Alt text"></p>
<h2 id="激励层"><a href="#激励层" class="headerlink" title="激励层"></a>激励层</h2><p>激励层就是把卷积层输出结果做非线性映射<br><img src="/2019/05/09/卷积网络/./激励层.png" alt="Alt text"></p>
<p>CNN(卷积网络)采用的激励函数一般为ReLU(y  = max (0,x)),它的特点是收获快，求梯度简单，但是比较脆弱<br><img src="/2019/05/09/卷积网络/./ReLU.png" alt="Alt text"></p>
<ul>
<li>不要使用sigmod(前馈网络常用的激励函数)</li>
<li>首先试ReLU</li>
<li>次选Leaky ReLU 或者Maxout</li>
<li>有时候Tanh(双曲正切)也可以</li>
</ul>
<h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>池化层夹在连续的卷积层中间， 用于压缩数据和参数的量，减小过拟合。<br>简而言之，如果输入是图像的话，那么池化层的最主要作用就是压缩图像。</p>
<p>这里再展开叙述池化层的具体作用。</p>
<ol>
<li><p>特征不变性，也就是我们在图像处理中经常提到的特征的尺度不变性，池化操作就是图像的resize，平时一张狗的图像被缩小了一倍我们还能认出这是一张狗的照片，这说明这张图像中仍保留着狗最重要的特征，我们一看就能判断图像中画的是一只狗，图像压缩时去掉的信息只是一些无关紧要的信息，而留下的信息则是具有尺度不变性的特征，是最能表达图像的特征。</p>
</li>
<li><p>特征降维，我们知道一幅图像含有的信息是很大的，特征也很多，但是有些信息对于我们做图像任务时没有太多用途或者有重复，我们可以把这类冗余信息去除，把最重要的特征抽取出来，这也是池化操作的一大作用。</p>
</li>
<li><p>在一定程度上防止过拟合，更方便优化。<br><img src="/2019/05/09/卷积网络/./池化层1.png" alt="Alt text"><br>池化层用的方法有Max pooling 和 average pooling，而实际用的较多的是Max pooling。一个做了最大化一个做了平均化。</p>
</li>
</ol>
<p>这里就说一下Max pooling，其实思想非常简单。<br><img src="/2019/05/09/卷积网络/./池化层2.png" alt="Alt text"><br>对于每个2<em>2的窗口选出最大的数作为输出矩阵的相应元素的值，比如输入矩阵第一个2</em>2窗口中最大的数是6，那么输出矩阵的第一个元素就是6，如此类推。</p>
<p>同理 verage pooling 就是将前面输出过来的数据做一个取平均值的操作，比如以stride = 2 的 2×2 为Mean Pooling Filter 。输出的元素就是对应的平均值</p>
<h2 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h2><p>两层之间所有神经元都有权重连接，通常全连接层在卷积神经网络尾部。也就是跟传统的神经网络神经元的连接方式是一样的：</p>
<h2 id="一般CNN结构"><a href="#一般CNN结构" class="headerlink" title="一般CNN结构"></a>一般CNN结构</h2><ol>
<li>INPUT</li>
<li>[[CONV -&gt; RELU]<em>N -&gt; POOL?]</em>M </li>
<li>[FC -&gt; RELU]*K</li>
<li>FC</li>
</ol>
<h2 id="训练算法"><a href="#训练算法" class="headerlink" title="训练算法"></a>训练算法</h2><ol>
<li>同一般机器学习算法，先定义Loss function，衡量和实际结果之间差距。</li>
<li>找到最小化损失函数的W和b， CNN中用的算法是SGD（随机梯度下降）</li>
</ol>
<p>##典型CNN网络</p>
<ul>
<li>LeNet，这是最早用于数字识别的CNN</li>
<li>AlexNet， 2012 ILSVRC比赛远超第2名的CNN，比</li>
<li>LeNet更深，用多层小卷积层叠加替换单大卷积层。</li>
<li>ZF Net， 2013 ILSVRC比赛冠军</li>
<li>GoogLeNet， 2014 ILSVRC比赛冠军</li>
<li>VGGNet， 2014 ILSVRC比赛中的模型，图像识别略差于GoogLeNet，但是在很多图像转化学习问题(比如object detection)上效果奇好</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/05/07/tensorflow首次模拟/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="目录">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="A.I.C.O">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/07/tensorflow首次模拟/" itemprop="url">tensorflow首次模拟</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-07T20:51:03+08:00">
                2019-05-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>@<a href="TENSORFLOW首次实践">TOC</a></p>
<h1 id="学习tensorflow的提前准备"><a href="#学习tensorflow的提前准备" class="headerlink" title="学习tensorflow的提前准备"></a>学习tensorflow的提前准备</h1><p>在学习使用tensorflow之前磕了半天的神经网络基础，然后开始首次实践手写板功能</p>
<h2 id="tensorflow的安装"><a href="#tensorflow的安装" class="headerlink" title="tensorflow的安装"></a>tensorflow的安装</h2><p>在cmd 中 用python语言安装即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow</span><br></pre></td></tr></table></figure></p>
<p>注：tensorflow的运行前提是numpy库的存在，记得更新numpy库<br>我们可以尝试运行一下<br>eg：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">&gt;&gt;&gt;hello = tf.constant(<span class="string">'hello,tensorflow'</span>)</span><br><span class="line">&gt;&gt;&gt;sess = tf.Session()</span><br><span class="line">&gt;&gt;&gt;print(sess.run(hello))</span><br><span class="line">hello,tensorflow</span><br></pre></td></tr></table></figure></p>
<p>当没有报错时，说明我们tensorflow安装成功</p>
<h2 id="tensorboard"><a href="#tensorboard" class="headerlink" title="tensorboard"></a>tensorboard</h2><p>tensorboard是一个可以让我们在训练网络的过程中通过仪表盘看到网络目前状态的表现情况的组件<br>在下载tensorflow时会一同打包下载<br>启动tensorboard需要在tensorflow环境下</p>
<p>#启动<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=(logs)        括号内为logs目录所在路径</span><br></pre></td></tr></table></figure></p>
<h2 id="MNIST数据集下载"><a href="#MNIST数据集下载" class="headerlink" title="MNIST数据集下载"></a>MNIST数据集下载</h2><p>MNIST是网上著名的公开数据集之一。官方网站在<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">http://yann.lecun.com/exdb/mnist/</a><br>我们从上面下载这4个数据文件</p>
<blockquote>
<p>train-images-idx3-ubyte.gz:  training set images (9912422 bytes)<br>train-labels-idx1-ubyte.gz:  training set labels (28881 bytes)<br>t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes)<br>t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)</p>
</blockquote>
<h1 id="使用tensorflow完成实验"><a href="#使用tensorflow完成实验" class="headerlink" title="使用tensorflow完成实验"></a>使用tensorflow完成实验</h1><p>我们首先从<strong>tensorflow</strong> 的官方 <strong>github</strong> 上 clone一哈<br>地址在<a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow</a><br>不得不说真的多，我克隆下来就用了半天<br>我们所用的文件目录在 tensorflow/tensorflow/examples/tutorials/mnist/中</p>
<p>将这个minst文件夹放在一个名为tensorflow的文件夹内，因为在<strong>fully_connected_feed.py</strong>文件中261行以及268行的两个目录索引为<strong>tensorflow/mnist/input_data</strong>和<strong>tensorflow/mnist/logs/fully_connected_feed</strong>。上一个表示训练数据集存放位置，所以我们从MNIST上下载的四个压缩包都放在<strong>input_date</strong>目录下,第二个是训练后生成的logs 所在位置，后面使用tensorboard的时候的logs目录即为此。</p>
<h2 id="第一个错误：Tensorflow-tensorflow-python-framework-errors-impl-NotFoundError-Failed-to-create-a-directory-tmp-tensorflow"><a href="#第一个错误：Tensorflow-tensorflow-python-framework-errors-impl-NotFoundError-Failed-to-create-a-directory-tmp-tensorflow" class="headerlink" title="第一个错误：Tensorflow-tensorflow.python.framework.errors_impl.NotFoundError: Failed to create a directory: /tmp\tensorflow"></a>第一个错误：Tensorflow-tensorflow.python.framework.errors_impl.NotFoundError: Failed to create a directory: /tmp\tensorflow</h2><p>抱着希望运行一哈,然后一大串warning之后一个报错。</p>
<blockquote>
<p>tensorflow.python.framework.errors_impl.NotFoundError: Failed to create a directory: /tmp\tensorflow</p>
</blockquote>
<p>这里大概意思就是代码中写的路径文件夹为<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这里我们把代码中的```/tmp```中的```/```改成其他,比如```..```或者```.</span><br></pre></td></tr></table></figure></p>
<p>问题代码出现在260行和267行</p>
<h2 id="第二个错误：Tensorflow-lt-urlopen-error-WinError-10060"><a href="#第二个错误：Tensorflow-lt-urlopen-error-WinError-10060" class="headerlink" title="第二个错误：Tensorflow-&lt;urlopen error [WinError 10060]"></a>第二个错误：Tensorflow-&lt;urlopen error [WinError 10060]</h2><p>再次执行后继续报错</p>
<blockquote>
<p>urllib.error.URLError: <urlopen error [winerror 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。></urlopen></p>
</blockquote>
<p>这就是我之前没把数据集放在指定的<strong>tensorflow/mnist/logs/fully_connected_feed</strong>目录下然后报的错误，放进去之后我的<strong>fully_connected_feed.py</strong>文件成功运行。</p>
<h1 id="将训练完毕后的情况用tensorboard展现出来"><a href="#将训练完毕后的情况用tensorboard展现出来" class="headerlink" title="将训练完毕后的情况用tensorboard展现出来"></a>将训练完毕后的情况用tensorboard展现出来</h1><p>终于完成训练了，然后我们希望将它展现出来</p>
<h2 id="tensorboard-报错OSError-Errno-22-Invalid-argument"><a href="#tensorboard-报错OSError-Errno-22-Invalid-argument" class="headerlink" title="tensorboard 报错OSError: [Errno 22] Invalid argument"></a>tensorboard 报错OSError: [Errno 22] Invalid argument</h2><p>这里我僵硬了半天，百度谷歌一波之后告诉我是<strong>tensorboard</strong>没在<strong>tensorflow</strong>环境下运行</p>
<ul>
<li>解决方法一<br>执行以下代码：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">activate tensorflow</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>我之前又手贱安了anaconda这个没用几次的软件，导致环境不同。然后这个代码自动在anaconda里执行，然后报错，我一气之下就把它给删了<br>然后再运行。直接告诉我指令不存在。。。想必问题定不出在此处</p>
<ul>
<li>解决方法二</li>
</ul>
<p>修改manager.py 文件<br><img src="/2019/05/07/tensorflow首次模拟/$O(NN8ET(S]`{2P5XZ3~N$V.jpg" alt><br>按如下方式修改：<br><img src="/2019/05/07/tensorflow首次模拟/xiugai.jpg" alt><br>完成后执行，成功，破费！<br>输入<a href="http://localhost:6006" target="_blank" rel="noopener">http://localhost:6006</a>即可查看训练中的各种指标数据。在训练过程中的变化情况<br><img src="/2019/05/07/tensorflow首次模拟/20190419214313883.jpg" alt></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">目录</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">目录</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
